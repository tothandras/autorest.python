# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import json
import sys
from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpResponse
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .. import models as _models
from .._model_base import AzureJSONEncoder, _deserialize
from .._serialization import Serializer
from .._vendor import OpenAIClientMixinABC, _format_url_section

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
if sys.version_info >= (3, 8):
    from typing import Literal  # pylint: disable=no-name-in-module, ungrouped-imports
else:
    from typing_extensions import Literal  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_open_ai_list_deployments_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/deployments"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_get_deployment_request(deployment_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/deployments/{deploymentId}"
    path_format_arguments = {
        "deploymentId": _SERIALIZER.url("deployment_id", deployment_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_update_deployment_request(deployment_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/deployments/{deploymentId}"
    path_format_arguments = {
        "deploymentId": _SERIALIZER.url("deployment_id", deployment_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_delete_deployment_request(deployment_id: str, **kwargs: Any) -> HttpRequest:
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    # Construct URL
    _url = "/deployments/{deploymentId}"
    path_format_arguments = {
        "deploymentId": _SERIALIZER.url("deployment_id", deployment_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, **kwargs)


def build_open_ai_list_files_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/files"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_upload_file_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/files"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_get_file_request(file_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/files/{fileId}"
    path_format_arguments = {
        "fileId": _SERIALIZER.url("file_id", file_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_delete_file_request(file_id: str, **kwargs: Any) -> HttpRequest:
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    # Construct URL
    _url = "/files/{fileId}"
    path_format_arguments = {
        "fileId": _SERIALIZER.url("file_id", file_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, **kwargs)


def build_open_ai_get_file_content_request(file_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/files/{fileId}/content"
    path_format_arguments = {
        "fileId": _SERIALIZER.url("file_id", file_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_import_file_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/files/import"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_list_fine_tunes_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/fine-tunes"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_create_fine_tune_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/fine-tunes"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_get_fine_tune_request(fine_tune_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/fine-tunes/{fineTuneId}"
    path_format_arguments = {
        "fineTuneId": _SERIALIZER.url("fine_tune_id", fine_tune_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_delete_fine_tune_request(fine_tune_id: str, **kwargs: Any) -> HttpRequest:
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    # Construct URL
    _url = "/fine-tunes/{fineTuneId}"
    path_format_arguments = {
        "fineTuneId": _SERIALIZER.url("fine_tune_id", fine_tune_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, **kwargs)


def build_open_ai_list_fine_tune_events_request(fine_tune_id: str, *, stream: bool, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/fine-tunes/{fineTuneId}/listFineTuneEvents"
    path_format_arguments = {
        "fineTuneId": _SERIALIZER.url("fine_tune_id", fine_tune_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["stream"] = _SERIALIZER.query("stream", stream, "bool")
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_cancel_fine_tune_request(fine_tune_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/fine-tunes/{fineTuneId}/cancel"
    path_format_arguments = {
        "fineTuneId": _SERIALIZER.url("fine_tune_id", fine_tune_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_list_models_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/models"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_open_ai_get_model_request(model_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: Literal["2022-06-01-preview"] = kwargs.pop(
        "api_version", _params.pop("api-version", "2022-06-01-preview")
    )
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/models/{model_id}"
    path_format_arguments = {
        "model_id": _SERIALIZER.url("model_id", model_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


class OpenAIClientOperationsMixin(OpenAIClientMixinABC):
    @distributed_trace
    def list_deployments(self, **kwargs: Any) -> _models.DeploymentList:
        """Gets the list of deployments owned by the Azure OpenAI resource.

        Gets the list of deployments owned by the Azure OpenAI resource.

        :return: DeploymentList. The DeploymentList is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.DeploymentList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DeploymentList] = kwargs.pop("cls", None)

        request = build_open_ai_list_deployments_request(
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.DeploymentList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get_deployment(self, deployment_id: str, **kwargs: Any) -> _models.Deployment:
        """Gets details for a single deployment specified by the given deployment_id.

        Gets details for a single deployment specified by the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :return: Deployment. The Deployment is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Deployment
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Deployment] = kwargs.pop("cls", None)

        request = build_open_ai_get_deployment_request(
            deployment_id=deployment_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.Deployment, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def update_deployment(
        self,
        deployment_id: str,
        resource: _models.Deployment,
        *,
        content_type: str = "application/merge-patch+json",
        **kwargs: Any
    ) -> _models.Deployment:
        """Updates the mutable details of the deployment with the given deployment_id.

        Updates the mutable details of the deployment with the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :param resource: The resource instance. Required.
        :type resource: ~azure.openai.python.models.Deployment
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/merge-patch+json".
        :paramtype content_type: str
        :return: Deployment. The Deployment is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Deployment
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_deployment(
        self, deployment_id: str, resource: JSON, *, content_type: str = "application/merge-patch+json", **kwargs: Any
    ) -> _models.Deployment:
        """Updates the mutable details of the deployment with the given deployment_id.

        Updates the mutable details of the deployment with the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :param resource: The resource instance. Required.
        :type resource: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/merge-patch+json".
        :paramtype content_type: str
        :return: Deployment. The Deployment is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Deployment
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_deployment(
        self, deployment_id: str, resource: IO, *, content_type: str = "application/merge-patch+json", **kwargs: Any
    ) -> _models.Deployment:
        """Updates the mutable details of the deployment with the given deployment_id.

        Updates the mutable details of the deployment with the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :param resource: The resource instance. Required.
        :type resource: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/merge-patch+json".
        :paramtype content_type: str
        :return: Deployment. The Deployment is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Deployment
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def update_deployment(
        self, deployment_id: str, resource: Union[_models.Deployment, JSON, IO], **kwargs: Any
    ) -> _models.Deployment:
        """Updates the mutable details of the deployment with the given deployment_id.

        Updates the mutable details of the deployment with the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :param resource: The resource instance. Is one of the following types: model, JSON, IO
         Required.
        :type resource: ~azure.openai.python.models.Deployment or JSON or IO
        :keyword content_type: This request has a JSON Merge Patch body. Default value is None.
        :paramtype content_type: str
        :return: Deployment. The Deployment is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Deployment
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Deployment] = kwargs.pop("cls", None)

        content_type = content_type or "application/merge-patch+json"
        _content = None
        if isinstance(resource, (IO, bytes)):
            _content = resource
        else:
            _content = json.dumps(resource, cls=AzureJSONEncoder)  # type: ignore

        request = build_open_ai_update_deployment_request(
            deployment_id=deployment_id,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            deserialized = _deserialize(_models.Deployment, response.json())

        if response.status_code == 201:
            deserialized = _deserialize(_models.Deployment, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_deployment(  # pylint: disable=inconsistent-return-statements
        self, deployment_id: str, **kwargs: Any
    ) -> None:
        """Deletes the deployment specified by the given deployment_id.

        Deletes the deployment specified by the given deployment_id.

        :param deployment_id: The identifier of the deployment. Required.
        :type deployment_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        request = build_open_ai_delete_deployment_request(
            deployment_id=deployment_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if cls:
            return cls(pipeline_response, None, {})

    @distributed_trace
    def list_files(self, **kwargs: Any) -> _models.FileList:
        """Gets a list of all files owned by the Azure OpenAI resource.
        These include user uploaded content like files with purpose "fine-tune" for training or
        validation of fine-tunes models as well as files that are generated by the
        service such as "fine-tune-results" which contains various metrics for the
        corresponding fine-tune job.

        Gets a list of all files owned by the Azure OpenAI resource.
        These include user uploaded content like files with purpose "fine-tune" for training or
        validation of fine-tunes models
        as well as files that are generated by the
        service such as "fine-tune-results" which contains various metrics for the
        corresponding fine-tune job.

        :return: FileList. The FileList is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FileList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.FileList] = kwargs.pop("cls", None)

        request = build_open_ai_list_files_request(
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.FileList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def upload_file(
        self, resource: _models.File, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.CustomResponseFields:
        """Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        :param resource: The resource instance. Required.
        :type resource: ~azure.openai.python.models.File
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: CustomResponseFields. The CustomResponseFields is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.CustomResponseFields
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def upload_file(
        self, resource: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.CustomResponseFields:
        """Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        :param resource: The resource instance. Required.
        :type resource: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: CustomResponseFields. The CustomResponseFields is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.CustomResponseFields
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def upload_file(
        self, resource: IO, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.CustomResponseFields:
        """Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        :param resource: The resource instance. Required.
        :type resource: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: CustomResponseFields. The CustomResponseFields is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.CustomResponseFields
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def upload_file(self, resource: Union[_models.File, JSON, IO], **kwargs: Any) -> _models.CustomResponseFields:
        """Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by uploading data from a local machine. Uploaded
        files can, for example, be used for training or evaluating fine-tuned models.

        :param resource: The resource instance. Is one of the following types: model, JSON, IO
         Required.
        :type resource: ~azure.openai.python.models.File or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: CustomResponseFields. The CustomResponseFields is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.CustomResponseFields
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.CustomResponseFields] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(resource, (IO, bytes)):
            _content = resource
        else:
            _content = json.dumps(resource, cls=AzureJSONEncoder)  # type: ignore

        request = build_open_ai_upload_file_request(
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))

        deserialized = _deserialize(_models.CustomResponseFields, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get_file(self, file_id: str, **kwargs: Any) -> _models.File:
        """Gets details for a single file specified by the given file_id including status,
        size, purpose, etc.

        Gets details for a single file specified by the given file_id including status,
        size, purpose, etc.

        :param file_id: The identity of this item. Required.
        :type file_id: str
        :return: File. The File is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.File
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.File] = kwargs.pop("cls", None)

        request = build_open_ai_get_file_request(
            file_id=file_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.File, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_file(self, file_id: str, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
        """Deletes the file with the given file_id.
        Deletion is also allowed if a file
        was used, e.g., as training file in a fine-tune job.

        Deletes the file with the given file_id.
        Deletion is also allowed if a file
        was used, e.g., as training file in a fine-tune job.

        :param file_id: The identity of this item. Required.
        :type file_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        request = build_open_ai_delete_file_request(
            file_id=file_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if cls:
            return cls(pipeline_response, None, {})

    @distributed_trace
    def get_file_content(self, file_id: str, **kwargs: Any) -> _models.FileContent:
        """Gets the content of the file specified by the given file_id.
        Files can be user
        uploaded content or generated by the service like result metrics of a fine-tune
        job.

        Gets the content of the file specified by the given file_id.
        Files can be user
        uploaded content or generated by the service like result metrics of a fine-tune
        job.

        :param file_id: The identity of this item. Required.
        :type file_id: str
        :return: FileContent. The FileContent is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FileContent
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.FileContent] = kwargs.pop("cls", None)

        request = build_open_ai_get_file_content_request(
            file_id=file_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.FileContent, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def import_file(
        self, body: _models.FileImport, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.File:
        """Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        :param body: expected schema for the body of the completion post request. Required.
        :type body: ~azure.openai.python.models.FileImport
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: File. The File is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.File
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def import_file(self, body: JSON, *, content_type: str = "application/json", **kwargs: Any) -> _models.File:
        """Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        :param body: expected schema for the body of the completion post request. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: File. The File is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.File
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def import_file(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> _models.File:
        """Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        :param body: expected schema for the body of the completion post request. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: File. The File is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.File
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def import_file(self, body: Union[_models.FileImport, JSON, IO], **kwargs: Any) -> _models.File:
        """Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        Creates a new file entity by importing data from a provided url. Uploaded files
        can, for example, be used for training or evaluating fine-tuned models.

        :param body: expected schema for the body of the completion post request. Is one of the
         following types: model, JSON, IO Required.
        :type body: ~azure.openai.python.models.FileImport or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: File. The File is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.File
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.File] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=AzureJSONEncoder)  # type: ignore

        request = build_open_ai_import_file_request(
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["location"] = self._deserialize("str", response.headers.get("location"))

        deserialized = _deserialize(_models.File, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list_fine_tunes(self, **kwargs: Any) -> _models.FineTuneList:
        """Gets a list of all fine-tune jobs owned by the Azure OpenAI resource.
        The details that are returned for each fine-tune job contain besides its
        identifier the base model, training and validation files, hyper parameters,
        time stamps, status and events.  Events are created when the job status
        changes, e.g. running or complete, and when results are uploaded.

        Gets a list of all fine-tune jobs owned by the Azure OpenAI resource.
        The details that are returned for each fine-tune job contain besides its
        identifier the base model, training and validation files, hyper parameters,
        time stamps, status and events. Events are created when the job status
        changes, e.g. running or complete, and when results are uploaded.

        :return: FineTuneList. The FineTuneList is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTuneList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.FineTuneList] = kwargs.pop("cls", None)

        request = build_open_ai_list_fine_tunes_request(
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.FineTuneList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def create_fine_tune(
        self, body: _models.FineTuneCreation, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.FineTune:
        """Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        :param body: Required.
        :type body: ~azure.openai.python.models.FineTuneCreation
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_fine_tune(
        self, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.FineTune:
        """Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        :param body: Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_fine_tune(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> _models.FineTune:
        """Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        :param body: Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create_fine_tune(self, body: Union[_models.FineTuneCreation, JSON, IO], **kwargs: Any) -> _models.FineTune:
        """Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        Creates a job that fine-tunes a specified model from a given training
        file.
        Response includes details of the enqueued job including job status and
        hyper parameters.
        The name of the fine-tuned model is added to the response
        once complete.

        :param body: Is one of the following types: model, JSON, IO Required.
        :type body: ~azure.openai.python.models.FineTuneCreation or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.FineTune] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=AzureJSONEncoder)  # type: ignore

        request = build_open_ai_create_fine_tune_request(
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["location"] = self._deserialize("str", response.headers.get("location"))

        deserialized = _deserialize(_models.FineTune, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get_fine_tune(self, fine_tune_id: str, **kwargs: Any) -> _models.FineTune:
        """Gets details for a single fine-tune job specified by the given
        fine_tune_id.
        The details contain the base model, training and validation
        files, hyper parameters, time stamps, status and events.
        Events are created
        when the job status changes, e.g. running or complete, and when results are
        uploaded.

        Gets details for a single fine-tune job specified by the given
        fine_tune_id.
        The details contain the base model, training and validation
        files, hyper parameters, time stamps, status and events.
        Events are created
        when the job status changes, e.g. running or complete, and when results are
        uploaded.

        :param fine_tune_id: The identity of this item. Required.
        :type fine_tune_id: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.FineTune] = kwargs.pop("cls", None)

        request = build_open_ai_get_fine_tune_request(
            fine_tune_id=fine_tune_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.FineTune, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_fine_tune(  # pylint: disable=inconsistent-return-statements
        self, fine_tune_id: str, **kwargs: Any
    ) -> None:
        """Deletes the fine-tune job specified by the given fine_tune_id.

        Deletes the fine-tune job specified by the given fine_tune_id.

        :param fine_tune_id: The identity of this item. Required.
        :type fine_tune_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        request = build_open_ai_delete_fine_tune_request(
            fine_tune_id=fine_tune_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if cls:
            return cls(pipeline_response, None, {})

    @distributed_trace
    def list_fine_tune_events(self, fine_tune_id: str, *, stream: bool, **kwargs: Any) -> _models.EventList:
        """List events for the fine-tune job specified by the given fine_tune_id.
        Events are created when the job status changes, e.g. running or
        complete, and when results are uploaded.

        List events for the fine-tune job specified by the given fine_tune_id.
        Events are created when the job status changes, e.g. running or
        complete, and when results are uploaded.

        :param fine_tune_id: The identity of this item. Required.
        :type fine_tune_id: str
        :keyword stream: A flag indicating whether to stream events for the fine-tune job. If set to
         true,
         events will be sent as data-only server-sent events as they become available. The stream will
         terminate with
         a data: [DONE] message when the job is finished (succeeded, cancelled, or failed).
         If set to false, only events generated so far will be returned.. Required.
        :paramtype stream: bool
        :return: EventList. The EventList is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.EventList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.EventList] = kwargs.pop("cls", None)

        request = build_open_ai_list_fine_tune_events_request(
            fine_tune_id=fine_tune_id,
            stream=stream,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.EventList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def cancel_fine_tune(self, fine_tune_id: str, **kwargs: Any) -> _models.FineTune:
        """Cancels the processing of the fine-tune job specified by the given fine_tune_id.

        Cancels the processing of the fine-tune job specified by the given fine_tune_id.

        :param fine_tune_id: The identity of this item. Required.
        :type fine_tune_id: str
        :return: FineTune. The FineTune is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.FineTune
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.FineTune] = kwargs.pop("cls", None)

        request = build_open_ai_cancel_fine_tune_request(
            fine_tune_id=fine_tune_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.FineTune, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list_models(self, **kwargs: Any) -> _models.ModelList:
        """Gets a list of all models that are accessible by the Azure OpenAI
        resource.
        These include base models as well as all successfully completed
        fine-tuned models owned by the Azure OpenAI resource.

        Gets a list of all models that are accessible by the Azure OpenAI
        resource.
        These include base models as well as all successfully completed
        fine-tuned models owned by the Azure OpenAI resource.

        :return: ModelList. The ModelList is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.ModelList
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.ModelList] = kwargs.pop("cls", None)

        request = build_open_ai_list_models_request(
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.ModelList, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get_model(self, model_id: str, **kwargs: Any) -> _models.Model:
        """Gets details for the model specified by the given model_id.

        Gets details for the model specified by the given model_id.

        :param model_id: The identity of this item. Required.
        :type model_id: str
        :return: Model. The Model is compatible with MutableMapping
        :rtype: ~azure.openai.python.models.Model
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Model] = kwargs.pop("cls", None)

        request = build_open_ai_get_model_request(
            model_id=model_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.Model, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore
