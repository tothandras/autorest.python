namespace: azure.openai
subnamespaceToClients: {}
clients:
  - name: OpenAIClient
    description: Azure OpenAI APIs for completions and search
    parameters:
      - &ref_0
        optional: false
        description: >-
          Supported Cognitive Services endpoints (protocol and hostname, for
          example:

          https://westus.api.cognitive.microsoft.com).
        clientName: endpoint
        inOverload: false
        restApiName: endpoint
        location: endpointPath
        type: &ref_1
          type: string
        implementation: Client
        skipUrlEncoding: true
      - type: &ref_16
          type: combined
          types:
            - type: Key
              policy:
                type: AzureKeyCredentialPolicy
                key: apiKey
            - type: OAuth2
              policy:
                type: BearerTokenCredentialPolicy
                credentialScopes: []
        optional: false
        description: Credential needed for the client to connect to Azure.
        clientName: credential
        location: other
        restApiName: credential
        implementation: Client
        skipUrlEncoding: true
        inOverload: false
      - &ref_2
        clientDefaultValue: 2022-06-01-preview
        optional: false
        description: The API version to use for this operation.
        clientName: api_version
        inOverload: false
        restApiName: api-version
        location: query
        type: &ref_6
          apiVersions: []
          clientDefaultValue: null
          type: constant
          value: 2022-06-01-preview
          valueType: &ref_3
            type: string
          xmlMetadata: {}
        implementation: Client
        skipUrlEncoding: false
        in_docstring: false
    operationGroups:
      - className: ''
        propertyName: ''
        operations:
          - name: embeddings
            description: Return the embeddings for a given prompt.
            url: /deployments/{deploymentId}/embeddings
            method: POST
            parameters:
              - *ref_0
              - optional: false
                description: deployment id of the deployed model
                clientName: deployment_id
                inOverload: false
                restApiName: deploymentId
                location: path
                type: *ref_1
                implementation: Method
                skipUrlEncoding: false
              - *ref_2
              - checkClientInput: false
                clientDefaultValue: application/json
                clientName: accept
                delimiter: null
                description: Accept header.
                explode: false
                groupedBy: null
                implementation: Method
                inDocstring: true
                inOverload: false
                inOverriden: false
                location: header
                optional: false
                restApiName: Accept
                skipUrlEncoding: false
                type: &ref_7
                  apiVersions: []
                  clientDefaultValue: null
                  type: constant
                  value: application/json
                  valueType: *ref_3
                  xmlMetadata: {}
              - checkClientInput: false
                clientDefaultValue: application/json
                clientName: content_type
                delimiter: null
                description: >-
                  Body parameter Content-Type. Known values are:
                  application/json.
                implementation: Method
                inDocstring: true
                inOverload: false
                inOverriden: false
                location: header
                optional: true
                restApiName: Content-Type
                type: *ref_3
              - checkClientInput: false
                clientDefaultValue: null
                clientName: user
                delimiter: null
                description: The ID of the end-user, for use in tracking and rate-limiting.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: input_type
                delimiter: null
                description: input type of embedding search to use
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: model
                delimiter: null
                description: ID of the model to use
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: input
                delimiter: null
                description: >-
                  An input to embed, encoded as a string, a list of strings, or
                  a list of token

                  lists
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: false
                restApiName: null
                skipUrlEncoding: false
                type: &ref_5
                  name: MyCombinedType
                  snakeCaseName: my_combined_type
                  description: Type of MyCombinedType
                  isPublic: false
                  type: combined
                  types:
                    - type: string
                    - type: list
                      elementType: *ref_1
                    - type: list
                      elementType: &ref_4
                        type: integer
                    - type: list
                      elementType: &ref_23
                        type: list
                        elementType: *ref_4
                  xmlMetadata: {}
            bodyParameter:
              contentTypes:
                - application/json
              type: &ref_22
                type: model
                name: EmbeddingsRequest
                description: ''
                parents: []
                discriminatedSubtypes: {}
                properties:
                  - clientName: user
                    restApiName: user
                    type: *ref_1
                    optional: true
                    description: >-
                      The ID of the end-user, for use in tracking and
                      rate-limiting.
                    readonly: false
                  - clientName: input_type
                    restApiName: input_type
                    type: *ref_1
                    optional: true
                    description: input type of embedding search to use
                    readonly: false
                  - clientName: model
                    restApiName: model
                    type: *ref_1
                    optional: true
                    description: ID of the model to use
                    readonly: false
                  - clientName: input
                    restApiName: input
                    type: *ref_5
                    optional: false
                    description: >-
                      An input to embed, encoded as a string, a list of strings,
                      or a list of token

                      lists
                    readonly: false
                snakeCaseName: ''
                base: json
              restApiName: body
              location: body
              optional: false
              description: ''
              clientName: body
              inOverload: false
              defaultContentType: application/json
              propertyToParameterName:
                user: user
                input_type: input_type
                model: model
                input: input
            responses:
              - headers: []
                statusCodes:
                  - 200
                discriminator: basic
                type: &ref_17
                  type: model
                  name: Embeddings
                  description: ''
                  parents: []
                  discriminatedSubtypes: {}
                  properties:
                    - clientName: object
                      restApiName: object
                      type: &ref_18
                        type: constant
                        value: list
                        valueType:
                          type: string
                      optional: false
                      description: ''
                      readonly: false
                    - clientName: data
                      restApiName: data
                      type: &ref_21
                        type: list
                        elementType: &ref_19
                          type: model
                          name: Embedding
                          description: ''
                          parents: []
                          discriminatedSubtypes: {}
                          properties:
                            - clientName: object
                              restApiName: object
                              type: &ref_20
                                type: constant
                                value: embedding
                                valueType:
                                  type: string
                              optional: false
                              description: ''
                              readonly: false
                            - clientName: embedding
                              restApiName: embedding
                              type: &ref_15
                                type: list
                                elementType: &ref_9
                                  type: float
                              optional: false
                              description: ''
                              readonly: false
                            - clientName: index
                              restApiName: index
                              type: &ref_8
                                type: integer
                              optional: false
                              description: ''
                              readonly: false
                          snakeCaseName: embedding
                          base: dpg
                      optional: false
                      description: ''
                      readonly: false
                  snakeCaseName: embeddings
                  base: dpg
            exceptions:
              - headers: []
                statusCodes:
                  - default
                discriminator: basic
            groupName: ''
            discriminator: basic
            isOverload: false
            overloads: []
            apiVersions:
              - null
          - name: completions
            description: Return the completions for a given prompt.
            url: /deployments/{deploymentId}/completions
            method: POST
            parameters:
              - *ref_0
              - optional: false
                description: deployment id of the deployed model
                clientName: deployment_id
                inOverload: false
                restApiName: deploymentId
                location: path
                type: *ref_1
                implementation: Method
                skipUrlEncoding: false
              - clientDefaultValue: 2022-06-01-preview
                optional: false
                description: The API version to use for this operation.
                clientName: api_version
                inOverload: false
                restApiName: api-version
                location: query
                type: *ref_6
                implementation: Client
                skipUrlEncoding: false
                in_docstring: false
              - checkClientInput: false
                clientDefaultValue: application/json
                clientName: accept
                delimiter: null
                description: Accept header.
                explode: false
                groupedBy: null
                implementation: Method
                inDocstring: true
                inOverload: false
                inOverriden: false
                location: header
                optional: false
                restApiName: Accept
                skipUrlEncoding: false
                type: *ref_7
              - checkClientInput: false
                clientDefaultValue: application/json
                clientName: content_type
                delimiter: null
                description: >-
                  Body parameter Content-Type. Known values are:
                  application/json.
                implementation: Method
                inDocstring: true
                inOverload: false
                inOverriden: false
                location: header
                optional: true
                restApiName: Content-Type
                type: *ref_3
              - checkClientInput: false
                clientDefaultValue: null
                clientName: prompt
                delimiter: null
                description: >-
                  An optional prompt to complete from, encoded as a string, a
                  list of strings, or

                  a list of token lists. Defaults to <|endoftext|>. The prompt
                  to complete from.

                  If you would like to provide multiple prompts, use the POST
                  variant of this

                  method. Note that <|endoftext|> is the document separator that
                  the model sees

                  during training, so if a prompt is not specified the model
                  will generate as if

                  from the beginning of a new document. Maximum allowed size of
                  string list is

                  2048.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: &ref_11
                  name: MyCombinedType
                  snakeCaseName: my_combined_type
                  description: Type of MyCombinedType
                  isPublic: false
                  type: combined
                  types:
                    - type: string
                    - type: list
                      elementType: *ref_1
                    - type: list
                      elementType: &ref_14
                        type: list
                        elementType: *ref_1
                  xmlMetadata: {}
              - checkClientInput: false
                clientDefaultValue: null
                clientName: max_tokens
                delimiter: null
                description: The maximum number of tokens to generate. Has minimum of 0.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_8
              - checkClientInput: false
                clientDefaultValue: null
                clientName: temperature
                delimiter: null
                description: >
                  What sampling temperature to use. Higher values means the
                  model will take more

                  risks. Try 0.9 for more creative applications, and 0 (argmax
                  sampling) for ones

                  with a well-defined answer.

                  We generally recommend using this or `top_p` but

                  not both.

                  Minimum of 0 and maximum of 2 allowed.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_9
              - checkClientInput: false
                clientDefaultValue: null
                clientName: top_p
                delimiter: null
                description: >
                  An alternative to sampling with temperature, called nucleus
                  sampling, where the

                  model considers the results of the tokens with top_p
                  probability mass. So 0.1

                  means only the tokens comprising the top 10% probability mass
                  are

                  considered.

                  We generally recommend using this or `temperature` but not

                  both.

                  Minimum of 0 and maximum of 1 allowed.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_9
              - checkClientInput: false
                clientDefaultValue: null
                clientName: logit_bias
                delimiter: null
                description: >-
                  Defaults to null. Modify the likelihood of specified tokens
                  appearing in the

                  completion. Accepts a json object that maps tokens (specified
                  by their token ID

                  in the GPT tokenizer) to an associated bias value from -100 to
                  100. You can use

                  this tokenizer tool (which works for both GPT-2 and GPT-3) to
                  convert text to

                  token IDs. Mathematically, the bias is added to the logits
                  generated by the

                  model prior to sampling. The exact effect will vary per model,
                  but values

                  between -1 and 1 should decrease or increase likelihood of
                  selection; values

                  like -100 or 100 should result in a ban or exclusive selection
                  of the relevant

                  token. As an example, you can pass {"50256" &#58; -100} to
                  prevent the

                  <|endoftext|> token from being generated.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: &ref_12
                  type: dict
                  elementType: *ref_8
              - checkClientInput: false
                clientDefaultValue: null
                clientName: user
                delimiter: null
                description: The ID of the end-user, for use in tracking and rate-limiting.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: 'n'
                delimiter: null
                description: >-
                  How many snippets to generate for each prompt. Minimum of 1
                  and maximum of 128

                  allowed.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_8
              - checkClientInput: false
                clientDefaultValue: null
                clientName: stream
                delimiter: null
                description: >-
                  Whether to enable streaming for this endpoint. If set, tokens
                  will be sent as

                  server-sent events as they become available.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: &ref_10
                  type: boolean
              - checkClientInput: false
                clientDefaultValue: null
                clientName: logprobs
                delimiter: null
                description: >-
                  Include the log probabilities on the `logprobs` most likely
                  tokens, as well the

                  chosen tokens. So for example, if `logprobs` is 10, the API
                  will return a list

                  of the 10 most likely tokens. If `logprobs` is 0, only the
                  chosen tokens will

                  have logprobs returned. Minimum of 0 and maximum of 100
                  allowed.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_8
              - checkClientInput: false
                clientDefaultValue: null
                clientName: model
                delimiter: null
                description: The name of the model to use
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: echo
                delimiter: null
                description: Echo back the prompt in addition to the completion
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_10
              - checkClientInput: false
                clientDefaultValue: null
                clientName: stop
                delimiter: null
                description: A sequence which indicates the end of the current document.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: &ref_13
                  name: MyCombinedType
                  snakeCaseName: my_combined_type
                  description: Type of MyCombinedType
                  isPublic: false
                  type: combined
                  types:
                    - type: string
                    - type: list
                      elementType: *ref_1
                  xmlMetadata: {}
              - checkClientInput: false
                clientDefaultValue: null
                clientName: completion_config
                delimiter: null
                description: Completion configuration
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_1
              - checkClientInput: false
                clientDefaultValue: null
                clientName: cache_level
                delimiter: null
                description: >-
                  can be used to disable any server-side caching, 0=no cache,
                  1=prompt prefix

                  enabled, 2=full cache
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_8
              - checkClientInput: false
                clientDefaultValue: null
                clientName: presence_penalty
                delimiter: null
                description: >-
                  How much to penalize new tokens based on their existing
                  frequency in the text

                  so far. Decreases the model's likelihood to repeat the same
                  line verbatim. Has

                  minimum of -2 and maximum of 2.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_9
              - checkClientInput: false
                clientDefaultValue: null
                clientName: frequency_penalty
                delimiter: null
                description: >-
                  How much to penalize new tokens based on whether they appear
                  in the text so

                  far. Increases the model's likelihood to talk about new
                  topics.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_9
              - checkClientInput: false
                clientDefaultValue: null
                clientName: best_of
                delimiter: null
                description: >-
                  How many generations to create server side, and display only
                  the best. Will not

                  stream intermediate progress if best_of > 1. Has maximum value
                  of 128.
                implementation: Method
                inDocstring: true
                inFlattenedBody: true
                inOverload: false
                inOverriden: false
                location: other
                optional: true
                restApiName: null
                skipUrlEncoding: false
                type: *ref_8
            bodyParameter:
              contentTypes:
                - application/json
              type: &ref_32
                type: model
                name: CompletionsRequest
                description: ''
                parents: []
                discriminatedSubtypes: {}
                properties:
                  - clientName: prompt
                    restApiName: prompt
                    type: *ref_11
                    optional: true
                    description: >-
                      An optional prompt to complete from, encoded as a string,
                      a list of strings, or

                      a list of token lists. Defaults to <|endoftext|>. The
                      prompt to complete from.

                      If you would like to provide multiple prompts, use the
                      POST variant of this

                      method. Note that <|endoftext|> is the document separator
                      that the model sees

                      during training, so if a prompt is not specified the model
                      will generate as if

                      from the beginning of a new document. Maximum allowed size
                      of string list is

                      2048.
                    readonly: false
                  - clientName: max_tokens
                    restApiName: max_tokens
                    type: *ref_8
                    optional: true
                    description: >-
                      The maximum number of tokens to generate. Has minimum of
                      0.
                    readonly: false
                  - clientName: temperature
                    restApiName: temperature
                    type: *ref_9
                    optional: true
                    description: >
                      What sampling temperature to use. Higher values means the
                      model will take more

                      risks. Try 0.9 for more creative applications, and 0
                      (argmax sampling) for ones

                      with a well-defined answer.

                      We generally recommend using this or `top_p` but

                      not both.

                      Minimum of 0 and maximum of 2 allowed.
                    readonly: false
                  - clientName: top_p
                    restApiName: top_p
                    type: *ref_9
                    optional: true
                    description: >
                      An alternative to sampling with temperature, called
                      nucleus sampling, where the

                      model considers the results of the tokens with top_p
                      probability mass. So 0.1

                      means only the tokens comprising the top 10% probability
                      mass are

                      considered.

                      We generally recommend using this or `temperature` but not

                      both.

                      Minimum of 0 and maximum of 1 allowed.
                    readonly: false
                  - clientName: logit_bias
                    restApiName: logit_bias
                    type: *ref_12
                    optional: true
                    description: >-
                      Defaults to null. Modify the likelihood of specified
                      tokens appearing in the

                      completion. Accepts a json object that maps tokens
                      (specified by their token ID

                      in the GPT tokenizer) to an associated bias value from
                      -100 to 100. You can use

                      this tokenizer tool (which works for both GPT-2 and GPT-3)
                      to convert text to

                      token IDs. Mathematically, the bias is added to the logits
                      generated by the

                      model prior to sampling. The exact effect will vary per
                      model, but values

                      between -1 and 1 should decrease or increase likelihood of
                      selection; values

                      like -100 or 100 should result in a ban or exclusive
                      selection of the relevant

                      token. As an example, you can pass {"50256" &#58; -100} to
                      prevent the

                      <|endoftext|> token from being generated.
                    readonly: false
                  - clientName: user
                    restApiName: user
                    type: *ref_1
                    optional: true
                    description: >-
                      The ID of the end-user, for use in tracking and
                      rate-limiting.
                    readonly: false
                  - clientName: 'n'
                    restApiName: 'n'
                    type: *ref_8
                    optional: true
                    description: >-
                      How many snippets to generate for each prompt. Minimum of
                      1 and maximum of 128

                      allowed.
                    readonly: false
                  - clientName: stream
                    restApiName: stream
                    type: *ref_10
                    optional: true
                    description: >-
                      Whether to enable streaming for this endpoint. If set,
                      tokens will be sent as

                      server-sent events as they become available.
                    readonly: false
                  - clientName: logprobs
                    restApiName: logprobs
                    type: *ref_8
                    optional: true
                    description: >-
                      Include the log probabilities on the `logprobs` most
                      likely tokens, as well the

                      chosen tokens. So for example, if `logprobs` is 10, the
                      API will return a list

                      of the 10 most likely tokens. If `logprobs` is 0, only the
                      chosen tokens will

                      have logprobs returned. Minimum of 0 and maximum of 100
                      allowed.
                    readonly: false
                  - clientName: model
                    restApiName: model
                    type: *ref_1
                    optional: true
                    description: The name of the model to use
                    readonly: false
                  - clientName: echo
                    restApiName: echo
                    type: *ref_10
                    optional: true
                    description: Echo back the prompt in addition to the completion
                    readonly: false
                  - clientName: stop
                    restApiName: stop
                    type: *ref_13
                    optional: true
                    description: >-
                      A sequence which indicates the end of the current
                      document.
                    readonly: false
                  - clientName: completion_config
                    restApiName: completionConfig
                    type: *ref_1
                    optional: true
                    description: Completion configuration
                    readonly: false
                  - clientName: cache_level
                    restApiName: cache_level
                    type: *ref_8
                    optional: true
                    description: >-
                      can be used to disable any server-side caching, 0=no
                      cache, 1=prompt prefix

                      enabled, 2=full cache
                    readonly: false
                  - clientName: presence_penalty
                    restApiName: presence_penalty
                    type: *ref_9
                    optional: true
                    description: >-
                      How much to penalize new tokens based on their existing
                      frequency in the text

                      so far. Decreases the model's likelihood to repeat the
                      same line verbatim. Has

                      minimum of -2 and maximum of 2.
                    readonly: false
                  - clientName: frequency_penalty
                    restApiName: frequency_penalty
                    type: *ref_9
                    optional: true
                    description: >-
                      How much to penalize new tokens based on whether they
                      appear in the text so

                      far. Increases the model's likelihood to talk about new
                      topics.
                    readonly: false
                  - clientName: best_of
                    restApiName: best_of
                    type: *ref_8
                    optional: true
                    description: >-
                      How many generations to create server side, and display
                      only the best. Will not

                      stream intermediate progress if best_of > 1. Has maximum
                      value of 128.
                    readonly: false
                snakeCaseName: ''
                base: json
              restApiName: body
              location: body
              optional: false
              description: ''
              clientName: body
              inOverload: false
              defaultContentType: application/json
              propertyToParameterName:
                prompt: prompt
                max_tokens: max_tokens
                temperature: temperature
                top_p: top_p
                logit_bias: logit_bias
                user: user
                'n': 'n'
                stream: stream
                logprobs: logprobs
                model: model
                echo: echo
                stop: stop
                completionConfig: completion_config
                cache_level: cache_level
                presence_penalty: presence_penalty
                frequency_penalty: frequency_penalty
                best_of: best_of
            responses:
              - headers:
                  - type: *ref_1
                    restApiName: apim-request-id
                statusCodes:
                  - 200
                discriminator: basic
                type: &ref_24
                  type: model
                  name: Completion
                  description: Expected response schema to completion request
                  parents: []
                  discriminatedSubtypes: {}
                  properties:
                    - clientName: apim_request_id
                      restApiName: apim-request-id
                      type: *ref_1
                      optional: false
                      description: Request ID for troubleshooting purposes
                      readonly: false
                    - clientName: id
                      restApiName: id
                      type: *ref_1
                      optional: true
                      description: Id for completion response
                      readonly: false
                    - clientName: object
                      restApiName: object
                      type: &ref_25
                        type: constant
                        value: text_completion
                        valueType:
                          type: string
                      optional: false
                      description: Object for completion response
                      readonly: false
                    - clientName: created
                      restApiName: created
                      type: *ref_8
                      optional: true
                      description: Created time for completion response
                      readonly: false
                    - clientName: model
                      restApiName: model
                      type: *ref_1
                      optional: true
                      description: Model used for completion response
                      readonly: false
                    - clientName: choices
                      restApiName: choices
                      type: &ref_31
                        type: list
                        elementType: &ref_26
                          type: model
                          name: Choice
                          description: Choice model within completion response
                          parents: []
                          discriminatedSubtypes: {}
                          properties:
                            - clientName: text
                              restApiName: text
                              type: *ref_1
                              optional: true
                              description: Generated text for given completion prompt
                              readonly: false
                            - clientName: index
                              restApiName: index
                              type: *ref_8
                              optional: true
                              description: Index
                              readonly: false
                            - clientName: logprobs
                              restApiName: logprobs
                              type: &ref_27
                                type: model
                                name: CompletionsLogProbsModel
                                description: LogProbs model within completion choice
                                parents: []
                                discriminatedSubtypes: {}
                                properties:
                                  - clientName: tokens
                                    restApiName: tokens
                                    type: *ref_14
                                    optional: true
                                    description: Tokens
                                    readonly: false
                                  - clientName: token_logprobs
                                    restApiName: token_logprobs
                                    type: *ref_15
                                    optional: true
                                    description: LogProbs of Tokens
                                    readonly: false
                                  - clientName: top_logprobs
                                    restApiName: top_logprobs
                                    type: &ref_29
                                      type: list
                                      elementType: &ref_28
                                        type: dict
                                        elementType: *ref_9
                                    optional: true
                                    description: Top LogProbs
                                    readonly: false
                                  - clientName: text_offset
                                    restApiName: text_offset
                                    type: &ref_30
                                      type: list
                                      elementType: *ref_8
                                    optional: true
                                    description: Text offset
                                    readonly: false
                                snakeCaseName: completions_log_probs_model
                                base: dpg
                              optional: true
                              description: Log Prob Model
                              readonly: false
                            - clientName: finish_reason
                              restApiName: finish_reason
                              type: *ref_1
                              optional: true
                              description: Reason for finishing
                              readonly: false
                          snakeCaseName: choice
                          base: dpg
                      optional: true
                      description: >-
                        Array of choices returned containing text completions to
                        prompts sent
                      readonly: false
                  snakeCaseName: completion
                  base: dpg
            exceptions:
              - headers: []
                statusCodes:
                  - default
                discriminator: basic
            groupName: ''
            discriminator: basic
            isOverload: false
            overloads: []
            apiVersions:
              - null
    url: '{endpoint}/openai'
    apiVersions: []
types:
  - *ref_1
  - *ref_16
  - *ref_17
  - *ref_18
  - *ref_19
  - *ref_20
  - *ref_9
  - *ref_15
  - *ref_8
  - *ref_21
  - *ref_22
  - *ref_4
  - *ref_23
  - *ref_5
  - *ref_24
  - *ref_25
  - *ref_26
  - *ref_27
  - *ref_14
  - *ref_28
  - *ref_29
  - *ref_30
  - *ref_31
  - *ref_32
  - *ref_11
  - *ref_12
  - *ref_10
  - *ref_13
  - *ref_3
  - *ref_6
  - *ref_7
